sample_bash_python_dag:
  dag_id: sample_bash_python_dag
  params: {}
  default_args:
    owner: airflow
    depends_on_past: false
    start_date: '2026-01-01'
    email_on_failure: false
    email_on_retry: false
    retries: 1
    retry_delay: 300.0
  schedule: 0 0 * * ? *
  tasks:
    create_directory:
      operator: airflow.providers.standard.operators.bash.BashOperator
      bash_command: mkdir -p /tmp/sample_dag && echo "Directory created"
      outlets: []
      params: {}
      priority_weight: 1
      retries: 1
      retry_delay: 300.0
      retry_exponential_backoff: false
      task_id: create_directory
      trigger_rule: all_success
      wait_for_downstream: false
      dependencies: []
    list_files:
      operator: airflow.providers.standard.operators.bash.BashOperator
      bash_command: ls -la /tmp/sample_dag
      outlets: []
      params: {}
      priority_weight: 1
      retries: 1
      retry_delay: 300.0
      retry_exponential_backoff: false
      task_id: list_files
      trigger_rule: all_success
      wait_for_downstream: false
      dependencies: [create_directory]
    process_data:
      operator: airflow.providers.standard.operators.python.PythonOperator
      op_args: []
      op_kwargs: {}
      outlets: []
      params: {}
      priority_weight: 1
      python_callable: python_and_bash.process_data
      retries: 1
      retry_delay: 300.0
      retry_exponential_backoff: false
      task_id: process_data
      trigger_rule: all_success
      wait_for_downstream: false
      dependencies: [list_files]
    cleanup:
      operator: airflow.providers.standard.operators.bash.BashOperator
      bash_command: rm -rf /tmp/sample_dag && echo "Cleanup completed"
      outlets: []
      params: {}
      priority_weight: 1
      retries: 1
      retry_delay: 300.0
      retry_exponential_backoff: false
      task_id: cleanup
      trigger_rule: all_success
      wait_for_downstream: false
      dependencies: [process_data]
  description: A sample DAG with Bash and Python operators
